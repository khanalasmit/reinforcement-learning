{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e999b5b4",
   "metadata": {},
   "source": [
    "## **Multi Armed Bandits**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfcd882",
   "metadata": {},
   "source": [
    "The Multi-Armed Bandit problem is an analogy to a gambler facing a row of slot machines, each with a different, unknown probability of winning. The challenge is to maximize their winnings by deciding which machine to play, how many times to play it, and when to switch to another machine. This scenario perfectly encapsulates the exploration-exploitation trade-off: exploring to find the machine with the highest reward but exploiting known information to maximize winnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c8e4b",
   "metadata": {},
   "source": [
    "* challange&rarr;maximize wining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ec94f",
   "metadata": {},
   "source": [
    "To creat a simulated multi armed bandit environment we start by assuming we have multiple slot machines each with own probablity of wining. Each probablity unknown to the agent and will need to learn during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119952e",
   "metadata": {},
   "source": [
    "### **Slot Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fba98",
   "metadata": {},
   "source": [
    "* Reward from an arm is 0 or 1.\n",
    "* Agent's goal &rarr; Accumlate maximum reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a825c33",
   "metadata": {},
   "source": [
    "### **Solving the problem**\n",
    "* Decayed epsilon greedy\n",
    "* Epsilon &rarr; Select random machine\n",
    "* 1-Epsilon &rarr; select best machine so far.\n",
    "* Epsilon decreses over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25cd77",
   "metadata": {},
   "source": [
    "```\n",
    "n_bandits=4\n",
    "true_bandits_probs=np.random.rand(n_bandits)\n",
    "\n",
    "n_iterations=100000\n",
    "epsilon=1.0\n",
    "min_epsilon=0.01\n",
    "epsilon_decay=0.999\n",
    "counts=np.zeros(n_bandits)#How many times each bandit was played\n",
    "values=np.zeros(n_bandits)#Estimated winning probablity of each bandit\n",
    "rewads=np.zeros(n_iterations)#reward history\n",
    "selected_arms=np.zeros(n_iterations,dtype=int)#Arm selection history\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb66bc",
   "metadata": {},
   "source": [
    "**Interaction Loop**\n",
    "```\n",
    "for i in range(n_iterations):\n",
    "    arm=epsilon_greedy()\n",
    "    reward=np.random.rand()<true_bandit_probs[arm]\n",
    "    rewards[i]=reward\n",
    "    selected_arm[i]=arm\n",
    "    counts[arm]+=1\n",
    "    values[arm]+=(reward-values[arm])/counts[arm]\n",
    "    epsilon=max(min_epsilon,epsilon*epsilon_decay)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f7094",
   "metadata": {},
   "source": [
    "**Analyzing selections**\n",
    "```\n",
    "selection_percentage=np.zeros((n_iterations,n_bandits))\n",
    "for i in range(n_iterations):\n",
    "    selection_percentage[i,selected_arms[i]]=1\n",
    "    selection_percentage=np.cumsum(selection_percentage,axis=0)/np.arange(1,n_iterations+1).reshape(-1,1)\n",
    "\n",
    "for arm in range(n_bandits):\n",
    "    plt.plot(selection_percentage[:,arm],label=f'Bandit #{arm+1}')\n",
    "    plt.xscale('log')\n",
    "    plt.title('Bandit Action Choices over time')\n",
    "    plt.xlabel('Epsilon Number')\n",
    "    plt.ylabel('Percentage of Bandit Selection(%)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "for i,prob in enumerate(true_bandtis_prob,1):\n",
    "    print(f\"Bandit #{i} ->{prob:.2f}\")\n",
    "\n",
    "```\n",
    "* Agent learns to select the bandit with the highest probablity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
