{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786ba8b8",
   "metadata": {},
   "source": [
    "![image](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b551554",
   "metadata": {},
   "source": [
    "**TD learning as weather forecasting**\\\n",
    "You can think of TD learning as weather forecasting, where predictions are constantly updated as new data like current weather conditions comes in, rather than waiting for the outcome of the whole day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692345f",
   "metadata": {},
   "source": [
    "**4. SARSA**\\\n",
    "Now, let's focus on SARSA, a specific TD Learning algorithm. SARSA stands for State-Action-Reward-State-Action, which outlines the data involved in its update process. As an on-policy method, SARSA learns the value of the policy it's currently following, adjusting its strategy based on the actions it takes. In SARSA, the agent learns by observing the current state, taking an action, receiving a reward, observing the next state, and then taking the next action. The value of the current state-action pair is updated based on this experience. Let's see how!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1be2f",
   "metadata": {},
   "source": [
    "![image](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75884d92",
   "metadata": {},
   "source": [
    "![image](5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76cde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d737409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\gymnasium\\envs\\registration.py:527: UserWarning: \u001b[33mWARN: Using the latest versioned environment `FrozenLake-v1` instead of the unversioned environment `FrozenLake`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env=gym.make('FrozenLake',is_slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63706338",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states=env.observation_space.n\n",
    "num_actions=env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c63005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=np.zeros((num_states,num_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c3688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(state,action,reward,next_state,next_action):\n",
    "    old_value=Q[state,action]\n",
    "    next_value=Q[next_state,next_action]\n",
    "    Q[state,action]=(1-alpha)*old_value+alpha*(reward+gamma*next_value)\n",
    "    \n",
    "alpha=0.01\n",
    "gamma=1\n",
    "num_episodes=1000\n",
    "for episode in range(num_episodes):\n",
    "    state,info=env.reset()\n",
    "    action=env.action_space.sample()\n",
    "    terminated=False\n",
    "    while not terminated:\n",
    "        next_state,reward,terminated,truncated,info=env.step(action)\n",
    "        next_action=env.action_space.sample()\n",
    "        update_q_table(state,action,reward,next_state,next_action)\n",
    "        state,action=next_state,next_action\n",
    "        \n",
    "def get_policy():\n",
    "    policy={state:np.argmax(Q[state]) for state in range(num_states)}\n",
    "    return policy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12912f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: np.int64(1), 1: np.int64(2), 2: np.int64(1), 3: np.int64(0), 4: np.int64(1), 5: np.int64(0), 6: np.int64(1), 7: np.int64(0), 8: np.int64(2), 9: np.int64(1), 10: np.int64(1), 11: np.int64(0), 12: np.int64(0), 13: np.int64(2), 14: np.int64(2), 15: np.int64(0)}\n"
     ]
    }
   ],
   "source": [
    "policy=get_policy()\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194656f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
